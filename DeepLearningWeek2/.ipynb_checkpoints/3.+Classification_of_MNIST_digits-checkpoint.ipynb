{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "teSVc4i7wTRh"
   },
   "source": [
    "# MNIST database of handwritten digits\n",
    "Dataset of 60,000 28x28 grayscale images of the 10 digits, along with a test set of 10,000 images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bLz1Ckvfvn6D"
   },
   "source": [
    "### Import TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CWrzVTLOvn6M",
    "outputId": "b2abba8b-b6f3-45cc-f8dd-f8d3f849243a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_uYeJgkNuXNC"
   },
   "source": [
    "### Set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lcASNsewsfQX"
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WjDBLreywya1"
   },
   "source": [
    "### Import dataset\n",
    "- This dataset can be imported\n",
    "- High level API Keras has some datasets available\n",
    "- You can look at all the datasets available here https://keras.io/datasets/\n",
    "- mnist.load_data() returns two tuples (x_train, y_train), (x_test, y_test):\n",
    "  - x_train, x_test: uint8 array of grayscale image data with shape (num_samples, 28, 28)\n",
    "  - y_train, y_test: uint8 array of digit labels (integers in range 0-9) with shape (num_samples,).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YWo16uM_yLYo",
    "outputId": "7ff19f5f-83e8-4210-fbec-7ab171d88d4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "11501568/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(trainX, trainY), (testX, testY) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tb-cerR2usfA"
   },
   "source": [
    "### Print shape and some values of label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lHctjiipyLY2",
    "outputId": "7161de6d-3790-4ab6-f4e3-860260974e6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "First 5 examples are:  [5 0 4 1 9]\n"
     ]
    }
   ],
   "source": [
    "print(trainY.shape)\n",
    "print('First 5 examples are: ', trainY[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "koAFciz0lWgy",
    "outputId": "b5411db3-1e10-4ab5-c30b-41fb6e94a68d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SIjqxbhWv1zv"
   },
   "source": [
    "### One-hot encode the class vector\n",
    "- convert class vectors (integers) to binary class matrix\n",
    "- convert trainY and testY\n",
    "- number of classes: 10\n",
    "- we are doing this to use categorical_crossentropy as loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R9vv-_gpyLY9"
   },
   "outputs": [],
   "source": [
    "trainY = tf.keras.utils.to_categorical(trainY, num_classes=10)\n",
    "testY = tf.keras.utils.to_categorical(testY, num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kmmA6rQjwX7m"
   },
   "source": [
    "Print shape and some values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-raS3VEryLZD",
    "outputId": "1e5b8bcf-6377-4991-8bf3-9acc5c32ed0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "First 5 examples now are:  [[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(trainY.shape)\n",
    "print('First 5 examples now are: ', trainY[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oM0sYEH2yLZJ"
   },
   "source": [
    "### Build the model in Keras\n",
    "- The Sequential model is a linear stack of layers.\n",
    "- The model needs to know what input shape it should expect. For this reason, the first layer in a Sequential model (and only the first, because following layers can do automatic shape inference) needs to receive information about its input shape.\n",
    "- You can also simply add layers via the .add() method\n",
    "- You can read more about it here https://keras.io/getting-started/sequential-model-guide/\n",
    "- Concepts of Batch Normalization will be covered in Upcoming sessions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E8rzL6z5yLZN"
   },
   "outputs": [],
   "source": [
    "# Initialize Sequential model\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "# Reshape data from 2D to 1D -> 28x28 to 784\n",
    "model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
    "\n",
    "# Normalize the data\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "# Add Dense Layer which provides 10 Outputs after applying softmax\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YJ38weGoqGEX"
   },
   "source": [
    "### Compile the model\n",
    "- Here we configure the model for training\n",
    "- We will specify an optimizer, loss function and a metrics\n",
    "- You can read more about it here https://keras.io/models/sequential/\n",
    "- We will learn about optimizers and Loss functions in the sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fOmhRmJjw86C"
   },
   "outputs": [],
   "source": [
    "# Comile the model\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WQXZi2mi_RfJ"
   },
   "source": [
    "### Fit the model\n",
    "- .fit() trains the model for a fixed number of epochs (iterations on a dataset)\n",
    "- An epoch is an iteration over the entire x and y data provided\n",
    "- batch_size is the number of samples per gradient update such as batch of 32 , 64 etc, here we utilise complete batch ( 60000 samples )\n",
    "- validation_data is the data on which to evaluate the loss and any model metrics at the end of each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SKvlQMuuyLZW",
    "outputId": "7c9e17cb-a65d-4caa-d5da-44979450c207"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.8356 - accuracy: 0.0816 - val_loss: 18.0596 - val_accuracy: 0.1362\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.7430 - accuracy: 0.0961 - val_loss: 12.3609 - val_accuracy: 0.1474\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.6543 - accuracy: 0.1132 - val_loss: 9.7076 - val_accuracy: 0.1630\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.5696 - accuracy: 0.1325 - val_loss: 8.0789 - val_accuracy: 0.1777\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.4888 - accuracy: 0.1552 - val_loss: 6.9476 - val_accuracy: 0.1946\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.4120 - accuracy: 0.1800 - val_loss: 6.1045 - val_accuracy: 0.2106\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.3389 - accuracy: 0.2061 - val_loss: 5.4472 - val_accuracy: 0.2279\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.2696 - accuracy: 0.2332 - val_loss: 4.9182 - val_accuracy: 0.2430\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.2039 - accuracy: 0.2602 - val_loss: 4.4821 - val_accuracy: 0.2583\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.1416 - accuracy: 0.2871 - val_loss: 4.1156 - val_accuracy: 0.2726\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0826 - accuracy: 0.3113 - val_loss: 3.8029 - val_accuracy: 0.2868\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0267 - accuracy: 0.3346 - val_loss: 3.5328 - val_accuracy: 0.2978\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.9737 - accuracy: 0.3574 - val_loss: 3.2972 - val_accuracy: 0.3144\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.9236 - accuracy: 0.3775 - val_loss: 3.0900 - val_accuracy: 0.3283\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.8760 - accuracy: 0.3962 - val_loss: 2.9064 - val_accuracy: 0.3440\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.8309 - accuracy: 0.4138 - val_loss: 2.7428 - val_accuracy: 0.3586\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.7881 - accuracy: 0.4315 - val_loss: 2.5963 - val_accuracy: 0.3737\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.7475 - accuracy: 0.4473 - val_loss: 2.4643 - val_accuracy: 0.3861\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.7089 - accuracy: 0.4620 - val_loss: 2.3452 - val_accuracy: 0.4005\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.6722 - accuracy: 0.4767 - val_loss: 2.2371 - val_accuracy: 0.4134\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.6374 - accuracy: 0.4908 - val_loss: 2.1387 - val_accuracy: 0.4282\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.6042 - accuracy: 0.5034 - val_loss: 2.0490 - val_accuracy: 0.4428\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.5726 - accuracy: 0.5156 - val_loss: 1.9669 - val_accuracy: 0.4577\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.5425 - accuracy: 0.5275 - val_loss: 1.8916 - val_accuracy: 0.4699\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.5139 - accuracy: 0.5386 - val_loss: 1.8224 - val_accuracy: 0.4827\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.4865 - accuracy: 0.5494 - val_loss: 1.7587 - val_accuracy: 0.4937\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.4604 - accuracy: 0.5594 - val_loss: 1.6998 - val_accuracy: 0.5050\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.4354 - accuracy: 0.5686 - val_loss: 1.6454 - val_accuracy: 0.5177\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.4116 - accuracy: 0.5778 - val_loss: 1.5950 - val_accuracy: 0.5300\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.3888 - accuracy: 0.5862 - val_loss: 1.5482 - val_accuracy: 0.5423\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.3669 - accuracy: 0.5945 - val_loss: 1.5047 - val_accuracy: 0.5521\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.3460 - accuracy: 0.6029 - val_loss: 1.4641 - val_accuracy: 0.5636\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.3259 - accuracy: 0.6096 - val_loss: 1.4263 - val_accuracy: 0.5743\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.3067 - accuracy: 0.6168 - val_loss: 1.3910 - val_accuracy: 0.5834\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.2882 - accuracy: 0.6233 - val_loss: 1.3579 - val_accuracy: 0.5931\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.2704 - accuracy: 0.6296 - val_loss: 1.3270 - val_accuracy: 0.6019\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.2534 - accuracy: 0.6357 - val_loss: 1.2979 - val_accuracy: 0.6099\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.2370 - accuracy: 0.6414 - val_loss: 1.2705 - val_accuracy: 0.6192\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.2212 - accuracy: 0.6472 - val_loss: 1.2448 - val_accuracy: 0.6261\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.2059 - accuracy: 0.6530 - val_loss: 1.2205 - val_accuracy: 0.6349\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.1912 - accuracy: 0.6581 - val_loss: 1.1976 - val_accuracy: 0.6438\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.1771 - accuracy: 0.6625 - val_loss: 1.1759 - val_accuracy: 0.6512\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.1634 - accuracy: 0.6670 - val_loss: 1.1554 - val_accuracy: 0.6578\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.1502 - accuracy: 0.6717 - val_loss: 1.1360 - val_accuracy: 0.6641\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.1375 - accuracy: 0.6765 - val_loss: 1.1176 - val_accuracy: 0.6692\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.1251 - accuracy: 0.6811 - val_loss: 1.1001 - val_accuracy: 0.6750\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.1132 - accuracy: 0.6849 - val_loss: 1.0834 - val_accuracy: 0.6819\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.1017 - accuracy: 0.6889 - val_loss: 1.0676 - val_accuracy: 0.6865\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.0905 - accuracy: 0.6930 - val_loss: 1.0525 - val_accuracy: 0.6915\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.0796 - accuracy: 0.6966 - val_loss: 1.0381 - val_accuracy: 0.6971\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2be45019d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX, trainY, validation_data=(testX, testY), epochs=50,\n",
    "          batch_size = trainX.shape[0])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "3. Classification_of_MNIST_digits.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
