{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bGyHWbOM70HN"
   },
   "source": [
    "## Image Classification\n",
    "\n",
    "\n",
    "Image classification is one of the important use cases in our daily life. Automotive, e-commerce, retail, manufacturing industries, security, surveillance, healthcare, farming etc., can have a wide application of image classification.\n",
    "\n",
    "**Objective:** In this notebook, we will build a neural network to classifiy the image based on the object present in the image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8LSdjqV35-j_"
   },
   "source": [
    "\n",
    "## Advanced techniques for training neural networks\n",
    "\n",
    "Weight Initialization\n",
    "\n",
    "Nonlinearity (different Activation functions)\n",
    "\n",
    "Optimizers(different optimizers)\n",
    "\n",
    "Batch Normalization\n",
    "\n",
    "Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XfL8u4jx82pG"
   },
   "source": [
    "### About Dataset\n",
    "\n",
    "\n",
    "Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255. The training and test data sets have 785 columns. The first column consists of the class labels (see above), and represents the article of clothing. The rest of the columns contain the pixel-values of the associated image.\n",
    "\n",
    "#### Labels\n",
    "\n",
    "Each training and test example is assigned to one of the following labels:\n",
    "\n",
    "0 T-shirt/top\n",
    "\n",
    "1 Trouser\n",
    "\n",
    "2 Pullover\n",
    "\n",
    "3 Dress\n",
    "\n",
    "4 Coat\n",
    "\n",
    "5 Sandal\n",
    "\n",
    "6 Shirt\n",
    "\n",
    "7 Sneaker\n",
    "\n",
    "8 Bag\n",
    "\n",
    "9 Ankle boot "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-XGznu8t6HBc"
   },
   "source": [
    "### Load dataset\n",
    "\n",
    "Fashion-MNIST dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "yeUlXwljJF8x"
   },
   "outputs": [],
   "source": [
    "%tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "y2ygqPGonpwu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3m64izx05_VU"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow \n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "9GEM4h0IoCfW",
    "outputId": "e327094f-f40f-4fb4-b977-b8581ba9bbfb"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'2.7.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "eAkQmLqP6I2W"
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VQGRwOCjqW2G",
    "outputId": "56998997-e594-4ebd-b320-8f8970ff0e74"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5HLg43FhqaTI",
    "outputId": "d2057d11-128f-403f-8e79-4e8663920148"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CmOeRO1OqhGu",
    "outputId": "050d149d-10e4-46c0-a2f4-67c02fb4594b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uwl3GH0BqjdX",
    "outputId": "d13df9d2-527e-4268-d369-59653e28357e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "Mr5bH4OY6Ndk",
    "outputId": "7ca7b04a-a2da-4002-90fa-75268af3d753"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  9\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(X_train[0])    # show first number in the dataset\n",
    "plt.show()\n",
    "print('Label: ', y_train[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "bcTZqYFj6PcB",
    "outputId": "51bdd727-20b1-4007-92d2-18a27f7ca092"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  9\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(X_test[0])    # show first number in the dataset\n",
    "plt.show()\n",
    "print('Label: ', y_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JZxmqqAa9Cz7"
   },
   "source": [
    "### Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "5TCY3Jnm6RHr"
   },
   "outputs": [],
   "source": [
    "# reshaping X data: (n, 28, 28) => (n, 784)\n",
    "X_train = X_train.reshape((X_train.shape[0], -1))\n",
    "X_test = X_test.reshape((X_test.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "oG06URdH6Vvv"
   },
   "outputs": [],
   "source": [
    "# converting y data into categorical (one-hot encoding)\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "71HK9T0P6Y2G",
    "outputId": "4dae4b81-858a-44a0-9c4a-d08bf93902e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (10000, 784) (60000, 10) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yb0Kx_ME6plD"
   },
   "source": [
    "### Basic NN model\n",
    "\n",
    "Naive MLP model without any alterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "weHT53gF6aFY"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "izZlXqJu6sdo"
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "3dCi-i296tuq"
   },
   "outputs": [],
   "source": [
    "  model.add(Dense(50, input_shape = (784, )))\n",
    "  model.add(Activation('sigmoid'))\n",
    "  model.add(Dense(50))\n",
    "  model.add(Activation('sigmoid'))\n",
    "  model.add(Dense(50))\n",
    "  model.add(Activation('sigmoid'))\n",
    "  model.add(Dense(50))\n",
    "  model.add(Activation('sigmoid'))\n",
    "  model.add(Dense(10))\n",
    "  model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "PJ5FUE916x2b"
   },
   "outputs": [],
   "source": [
    "sgd = optimizers.SGD(learning_rate = 0.01)\n",
    "model.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zl34l0jR6zH-",
    "outputId": "aa7b0616-8fab-4b57-f566-fec524c1c370"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "300/300 [==============================] - 3s 4ms/step - loss: 2.3236 - accuracy: 0.0955\n",
      "Epoch 2/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.3010 - accuracy: 0.1249\n",
      "Epoch 3/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2988 - accuracy: 0.1367\n",
      "Epoch 4/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2968 - accuracy: 0.1600\n",
      "Epoch 5/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2948 - accuracy: 0.2481\n",
      "Epoch 6/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2927 - accuracy: 0.2335\n",
      "Epoch 7/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2905 - accuracy: 0.2317\n",
      "Epoch 8/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2881 - accuracy: 0.2749\n",
      "Epoch 9/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2854 - accuracy: 0.3074\n",
      "Epoch 10/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2821 - accuracy: 0.3000\n",
      "Epoch 11/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2780 - accuracy: 0.3251\n",
      "Epoch 12/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2728 - accuracy: 0.3197\n",
      "Epoch 13/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2662 - accuracy: 0.3325\n",
      "Epoch 14/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2572 - accuracy: 0.3153\n",
      "Epoch 15/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2452 - accuracy: 0.3088\n",
      "Epoch 16/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2284 - accuracy: 0.3021\n",
      "Epoch 17/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2036 - accuracy: 0.2875\n",
      "Epoch 18/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.1667 - accuracy: 0.2609\n",
      "Epoch 19/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.1131 - accuracy: 0.2494\n",
      "Epoch 20/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.0405 - accuracy: 0.2451\n",
      "Epoch 21/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.9557 - accuracy: 0.2456\n",
      "Epoch 22/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.8742 - accuracy: 0.2450\n",
      "Epoch 23/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.8082 - accuracy: 0.2527\n",
      "Epoch 24/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.7601 - accuracy: 0.2714\n",
      "Epoch 25/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.7258 - accuracy: 0.2869\n",
      "Epoch 26/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.7007 - accuracy: 0.3003\n",
      "Epoch 27/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.6804 - accuracy: 0.3187\n",
      "Epoch 28/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.6627 - accuracy: 0.3515\n",
      "Epoch 29/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.6468 - accuracy: 0.3760\n",
      "Epoch 30/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.6323 - accuracy: 0.3532\n",
      "Epoch 31/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.6186 - accuracy: 0.3674\n",
      "Epoch 32/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.6063 - accuracy: 0.3592\n",
      "Epoch 33/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.5949 - accuracy: 0.3603\n",
      "Epoch 34/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.5839 - accuracy: 0.3835\n",
      "Epoch 35/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.5736 - accuracy: 0.3729\n",
      "Epoch 36/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.5641 - accuracy: 0.3596\n",
      "Epoch 37/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.5550 - accuracy: 0.3666\n",
      "Epoch 38/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.5467 - accuracy: 0.3896\n",
      "Epoch 39/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.5383 - accuracy: 0.3778\n",
      "Epoch 40/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.5304 - accuracy: 0.3851\n",
      "Epoch 41/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.5225 - accuracy: 0.3977\n",
      "Epoch 42/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.5133 - accuracy: 0.4134\n",
      "Epoch 43/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.5034 - accuracy: 0.3951\n",
      "Epoch 44/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.4912 - accuracy: 0.4075\n",
      "Epoch 45/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.4770 - accuracy: 0.4222\n",
      "Epoch 46/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.4567 - accuracy: 0.4317\n",
      "Epoch 47/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.4342 - accuracy: 0.4321\n",
      "Epoch 48/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.4114 - accuracy: 0.4394\n",
      "Epoch 49/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.3875 - accuracy: 0.4490\n",
      "Epoch 50/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.3644 - accuracy: 0.4679\n",
      "Epoch 51/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.3439 - accuracy: 0.4772\n",
      "Epoch 52/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.3251 - accuracy: 0.4855\n",
      "Epoch 53/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.3078 - accuracy: 0.4939\n",
      "Epoch 54/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.2925 - accuracy: 0.4986\n",
      "Epoch 55/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.2776 - accuracy: 0.5056\n",
      "Epoch 56/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.2648 - accuracy: 0.5065\n",
      "Epoch 57/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.2525 - accuracy: 0.5104\n",
      "Epoch 58/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.2418 - accuracy: 0.5117\n",
      "Epoch 59/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.2321 - accuracy: 0.5139\n",
      "Epoch 60/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.2215 - accuracy: 0.5146\n",
      "Epoch 61/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.2128 - accuracy: 0.5171\n",
      "Epoch 62/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.2038 - accuracy: 0.5149\n",
      "Epoch 63/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.1959 - accuracy: 0.5157\n",
      "Epoch 64/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.1886 - accuracy: 0.5238\n",
      "Epoch 65/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.1806 - accuracy: 0.5334\n",
      "Epoch 66/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.1713 - accuracy: 0.5330\n",
      "Epoch 67/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.1670 - accuracy: 0.5307\n",
      "Epoch 68/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.1584 - accuracy: 0.5352\n",
      "Epoch 69/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.1521 - accuracy: 0.5252\n",
      "Epoch 70/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.1460 - accuracy: 0.5400\n",
      "Epoch 71/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.1386 - accuracy: 0.5340\n",
      "Epoch 72/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.1346 - accuracy: 0.5560\n",
      "Epoch 73/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.1299 - accuracy: 0.5418\n",
      "Epoch 74/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.1286 - accuracy: 0.5367\n",
      "Epoch 75/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.1224 - accuracy: 0.5443\n",
      "Epoch 76/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.1169 - accuracy: 0.5509\n",
      "Epoch 77/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.1085 - accuracy: 0.5615\n",
      "Epoch 78/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.1039 - accuracy: 0.5630\n",
      "Epoch 79/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.0960 - accuracy: 0.5771\n",
      "Epoch 80/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.0868 - accuracy: 0.5777\n",
      "Epoch 81/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.0799 - accuracy: 0.5916\n",
      "Epoch 82/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.0740 - accuracy: 0.5890\n",
      "Epoch 83/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.0738 - accuracy: 0.5860\n",
      "Epoch 84/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.0637 - accuracy: 0.5932\n",
      "Epoch 85/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.0544 - accuracy: 0.6197\n",
      "Epoch 86/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.0478 - accuracy: 0.6205\n",
      "Epoch 87/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.0429 - accuracy: 0.6245\n",
      "Epoch 88/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.0371 - accuracy: 0.6121\n",
      "Epoch 89/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.0271 - accuracy: 0.6291\n",
      "Epoch 90/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.0206 - accuracy: 0.6374\n",
      "Epoch 91/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.0169 - accuracy: 0.6296\n",
      "Epoch 92/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.0088 - accuracy: 0.6363\n",
      "Epoch 93/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.0026 - accuracy: 0.6352\n",
      "Epoch 94/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.9987 - accuracy: 0.6467\n",
      "Epoch 95/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.9910 - accuracy: 0.6393\n",
      "Epoch 96/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.9811 - accuracy: 0.6458\n",
      "Epoch 97/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.9774 - accuracy: 0.6387\n",
      "Epoch 98/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.9686 - accuracy: 0.6500\n",
      "Epoch 99/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.9634 - accuracy: 0.6486\n",
      "Epoch 100/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.9531 - accuracy: 0.6540\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size = 200, epochs = 100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rhl0xqgR62ei",
    "outputId": "7d8aa549-c3ac-4ae1-e638-e9ca70647c76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.9799 - accuracy: 0.6383\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6PSheNKy66Iu",
    "outputId": "25620bd7-e083-4d12-b70e-21762a1d0c70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.6383000016212463\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy: ', results[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3V7kN5-f7IHv"
   },
   "source": [
    "### 1. Weight Initialization\n",
    "\n",
    "Changing weight initialization scheme can significantly improve training of the model by preventing vanishing gradient problem up to some degree\n",
    "\n",
    "Ref: https://keras.io/initializers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "7il0ZpZZ67GP"
   },
   "outputs": [],
   "source": [
    "# from now on, create a function to generate (return) models\n",
    "def mlp_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(50, input_shape = (784, ), kernel_initializer='he_normal'))     # use he_normal initializer\n",
    "    model.add(Activation('sigmoid'))    \n",
    "    model.add(Dense(50, kernel_initializer='he_normal'))                            # use he_normal initializer\n",
    "    model.add(Activation('sigmoid'))    \n",
    "    model.add(Dense(50, kernel_initializer='he_normal'))                            # use he_normal initializer\n",
    "    model.add(Activation('sigmoid'))    \n",
    "    model.add(Dense(50, kernel_initializer='he_normal'))                            # use he_normal initializer\n",
    "    model.add(Activation('sigmoid'))    \n",
    "    model.add(Dense(10, kernel_initializer='he_normal'))                            # use he_normal initializer\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    sgd = optimizers.SGD(learning_rate = 0.001)\n",
    "    model.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9iOQeOzR7Q2O",
    "outputId": "b59f94cc-7902-470d-b607-9c1e40b67ccb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "300/300 [==============================] - 2s 4ms/step - loss: 2.4380 - accuracy: 0.1000\n",
      "Epoch 2/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.3521 - accuracy: 0.1035\n",
      "Epoch 3/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.3189 - accuracy: 0.1352\n",
      "Epoch 4/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.3040 - accuracy: 0.1442\n",
      "Epoch 5/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2964 - accuracy: 0.1612\n",
      "Epoch 6/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2921 - accuracy: 0.1795\n",
      "Epoch 7/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2893 - accuracy: 0.2181\n",
      "Epoch 8/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2873 - accuracy: 0.2481\n",
      "Epoch 9/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2857 - accuracy: 0.2914\n",
      "Epoch 10/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2843 - accuracy: 0.3370\n",
      "Epoch 11/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2830 - accuracy: 0.3575\n",
      "Epoch 12/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2817 - accuracy: 0.3805\n",
      "Epoch 13/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2805 - accuracy: 0.3993\n",
      "Epoch 14/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2792 - accuracy: 0.3999\n",
      "Epoch 15/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2780 - accuracy: 0.4230\n",
      "Epoch 16/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2768 - accuracy: 0.4342\n",
      "Epoch 17/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2755 - accuracy: 0.4420\n",
      "Epoch 18/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2742 - accuracy: 0.4396\n",
      "Epoch 19/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2729 - accuracy: 0.4592\n",
      "Epoch 20/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2715 - accuracy: 0.4364\n",
      "Epoch 21/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2701 - accuracy: 0.4614\n",
      "Epoch 22/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2688 - accuracy: 0.4652\n",
      "Epoch 23/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2674 - accuracy: 0.4616\n",
      "Epoch 24/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2660 - accuracy: 0.4712\n",
      "Epoch 25/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2646 - accuracy: 0.4731\n",
      "Epoch 26/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2631 - accuracy: 0.4561\n",
      "Epoch 27/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2617 - accuracy: 0.4742\n",
      "Epoch 28/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2602 - accuracy: 0.4728\n",
      "Epoch 29/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2587 - accuracy: 0.4590\n",
      "Epoch 30/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2571 - accuracy: 0.4683\n",
      "Epoch 31/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2555 - accuracy: 0.4612\n",
      "Epoch 32/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2539 - accuracy: 0.4721\n",
      "Epoch 33/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2522 - accuracy: 0.4280\n",
      "Epoch 34/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2504 - accuracy: 0.4311\n",
      "Epoch 35/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2485 - accuracy: 0.4523\n",
      "Epoch 36/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2466 - accuracy: 0.4209\n",
      "Epoch 37/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2446 - accuracy: 0.4551\n",
      "Epoch 38/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2425 - accuracy: 0.4393\n",
      "Epoch 39/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2404 - accuracy: 0.4202\n",
      "Epoch 40/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2382 - accuracy: 0.4090\n",
      "Epoch 41/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2360 - accuracy: 0.4218\n",
      "Epoch 42/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2337 - accuracy: 0.4127\n",
      "Epoch 43/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2313 - accuracy: 0.3970\n",
      "Epoch 44/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2289 - accuracy: 0.3984\n",
      "Epoch 45/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2265 - accuracy: 0.3989\n",
      "Epoch 46/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2240 - accuracy: 0.3821\n",
      "Epoch 47/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2214 - accuracy: 0.3964\n",
      "Epoch 48/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2188 - accuracy: 0.3865\n",
      "Epoch 49/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2161 - accuracy: 0.3845\n",
      "Epoch 50/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2133 - accuracy: 0.3745\n",
      "Epoch 51/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2105 - accuracy: 0.3841\n",
      "Epoch 52/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2075 - accuracy: 0.3637\n",
      "Epoch 53/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2045 - accuracy: 0.3668\n",
      "Epoch 54/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2013 - accuracy: 0.3603\n",
      "Epoch 55/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.1981 - accuracy: 0.3648\n",
      "Epoch 56/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.1947 - accuracy: 0.3551\n",
      "Epoch 57/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.1912 - accuracy: 0.3550\n",
      "Epoch 58/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.1876 - accuracy: 0.3564\n",
      "Epoch 59/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.1838 - accuracy: 0.3613\n",
      "Epoch 60/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.1799 - accuracy: 0.3532\n",
      "Epoch 61/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.1759 - accuracy: 0.3592\n",
      "Epoch 62/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.1717 - accuracy: 0.3501\n",
      "Epoch 63/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.1674 - accuracy: 0.3507\n",
      "Epoch 64/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.1629 - accuracy: 0.3476\n",
      "Epoch 65/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.1582 - accuracy: 0.3459\n",
      "Epoch 66/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.1534 - accuracy: 0.3521\n",
      "Epoch 67/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.1484 - accuracy: 0.3448\n",
      "Epoch 68/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.1431 - accuracy: 0.3347\n",
      "Epoch 69/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.1376 - accuracy: 0.3486\n",
      "Epoch 70/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.1320 - accuracy: 0.3335\n",
      "Epoch 71/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.1261 - accuracy: 0.3441\n",
      "Epoch 72/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.1201 - accuracy: 0.3370\n",
      "Epoch 73/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.1139 - accuracy: 0.3325\n",
      "Epoch 74/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.1075 - accuracy: 0.3370\n",
      "Epoch 75/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.1009 - accuracy: 0.3320\n",
      "Epoch 76/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.0942 - accuracy: 0.3303\n",
      "Epoch 77/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.0873 - accuracy: 0.3438\n",
      "Epoch 78/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.0802 - accuracy: 0.3275\n",
      "Epoch 79/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.0730 - accuracy: 0.3400\n",
      "Epoch 80/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.0656 - accuracy: 0.3309\n",
      "Epoch 81/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.0580 - accuracy: 0.3345\n",
      "Epoch 82/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.0502 - accuracy: 0.3400\n",
      "Epoch 83/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.0423 - accuracy: 0.3274\n",
      "Epoch 84/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.0343 - accuracy: 0.3383\n",
      "Epoch 85/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.0261 - accuracy: 0.3399\n",
      "Epoch 86/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.0179 - accuracy: 0.3411\n",
      "Epoch 87/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.0095 - accuracy: 0.3325\n",
      "Epoch 88/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.0010 - accuracy: 0.3395\n",
      "Epoch 89/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.9924 - accuracy: 0.3426\n",
      "Epoch 90/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.9837 - accuracy: 0.3446\n",
      "Epoch 91/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.9750 - accuracy: 0.3411\n",
      "Epoch 92/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.9662 - accuracy: 0.3401\n",
      "Epoch 93/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.9575 - accuracy: 0.3397\n",
      "Epoch 94/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.9487 - accuracy: 0.3469\n",
      "Epoch 95/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.9399 - accuracy: 0.3504\n",
      "Epoch 96/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.9312 - accuracy: 0.3524\n",
      "Epoch 97/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.9225 - accuracy: 0.3536\n",
      "Epoch 98/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.9138 - accuracy: 0.3530\n",
      "Epoch 99/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.9053 - accuracy: 0.3561\n",
      "Epoch 100/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.8968 - accuracy: 0.3577\n"
     ]
    }
   ],
   "source": [
    "model = mlp_model()\n",
    "history = model.fit(X_train, y_train, batch_size=200, epochs = 100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ThB85Acn7SFu",
    "outputId": "eefcb90d-6890-4a61-eee6-03e583110ed4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 1.8951 - accuracy: 0.3591\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Iq5a7na67UgU",
    "outputId": "4d630a10-1955-4ad3-eedf-0ac6c0137206"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.35910001397132874\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy: ', results[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c5M6EHv17YUV"
   },
   "source": [
    "### 2. Nonlinearity (Activation function)\n",
    "\n",
    "Sigmoid functions suffer from gradient vanishing problem, making training slower\n",
    "\n",
    "There are many choices apart from sigmoid and tanh; try many of them!\n",
    "\n",
    "'relu' (rectified linear unit) is one of the most popular ones\n",
    "\n",
    "Ref: https://keras.io/activations/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "BuuRRvxL7WU1"
   },
   "outputs": [],
   "source": [
    "def mlp_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(50, input_shape = (784, )))\n",
    "    model.add(Activation('relu'))    \n",
    "    model.add(Dense(50))\n",
    "    model.add(Activation('relu'))    \n",
    "    model.add(Dense(50))\n",
    "    model.add(Activation('relu'))    \n",
    "    model.add(Dense(50))\n",
    "    model.add(Activation('relu'))    \n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    sgd = optimizers.SGD(learning_rate = 0.001)\n",
    "    model.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LHqen6477eRZ",
    "outputId": "a41ec3e9-ad52-4674-a117-acd3aa401757"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 1.1856 - accuracy: 0.6987\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.6001 - accuracy: 0.7846\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.5343 - accuracy: 0.8074\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.4956 - accuracy: 0.8206\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4685 - accuracy: 0.8302\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.4479 - accuracy: 0.8364\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.4339 - accuracy: 0.8430\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4227 - accuracy: 0.8456\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.4116 - accuracy: 0.8496\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.4039 - accuracy: 0.8530\n"
     ]
    }
   ],
   "source": [
    "model = mlp_model()\n",
    "history = model.fit(X_train, y_train, epochs = 10, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LLrEe_Kn7fha",
    "outputId": "087c69a6-e520-4135-c12f-133384900186"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.4554 - accuracy: 0.8322\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BBUqrqSd7heP",
    "outputId": "64accf12-c58d-429f-bc8e-bca6ae946cac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.8321999907493591\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy: ', results[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lp_-o2ug70fF"
   },
   "source": [
    "### 3. Batch Normalization\n",
    "\n",
    "Batch Normalization, one of the methods to prevent the \"internal covariance shift\" problem, has proven to be highly effective\n",
    "\n",
    "Normalize each mini-batch before nonlinearity\n",
    "\n",
    "Ref: https://keras.io/optimizers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "buhn2kOY7yg8"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization, Dropout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8YrSd0LT78Yi"
   },
   "source": [
    "Batch normalization layer is usually inserted after dense/convolution and before nonlinearity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "10InY0e_77M7"
   },
   "outputs": [],
   "source": [
    "def mlp_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(50, input_shape = (784, )))\n",
    "    model.add(BatchNormalization())                    \n",
    "    model.add(Activation('relu'))    \n",
    "    model.add(Dense(50))\n",
    "    model.add(BatchNormalization())                    \n",
    "    model.add(Activation('relu'))    \n",
    "    model.add(Dense(50))\n",
    "    model.add(BatchNormalization())                    \n",
    "    model.add(Activation('relu'))    \n",
    "    model.add(Dense(50))\n",
    "    model.add(BatchNormalization())                    \n",
    "    model.add(Activation('relu'))    \n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    sgd = optimizers.SGD(learning_rate = 0.001)\n",
    "    model.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jOCywkTg79_W",
    "outputId": "4d659c7b-0145-4652-f1d9-46c8e77148a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 11s 5ms/step - loss: 1.2747 - accuracy: 0.6119\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.8264 - accuracy: 0.7469\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.6943 - accuracy: 0.7778\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.6324 - accuracy: 0.7937\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.5886 - accuracy: 0.8047\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.5580 - accuracy: 0.8123\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.5349 - accuracy: 0.8176\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.5157 - accuracy: 0.8249\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.5047 - accuracy: 0.8278\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.4898 - accuracy: 0.8329\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.4759 - accuracy: 0.8356\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.4650 - accuracy: 0.8395\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.4584 - accuracy: 0.8404\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.4501 - accuracy: 0.8449\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.4452 - accuracy: 0.8460\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.4357 - accuracy: 0.8481\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.4302 - accuracy: 0.8503\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.4274 - accuracy: 0.8508\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.4207 - accuracy: 0.8537\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.4110 - accuracy: 0.8578\n"
     ]
    }
   ],
   "source": [
    "model = mlp_model()\n",
    "history = model.fit(X_train, y_train, epochs = 20, verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gGodrhsc8AW7",
    "outputId": "082c15e5-d909-449e-d2eb-bb87a012a628"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.4017 - accuracy: 0.8545\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zDnDxm8r8Bt0",
    "outputId": "3ed94494-acde-48eb-f04e-5287aa1be3da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.8544999957084656\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy: ', results[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ElSuYRBH8yim"
   },
   "source": [
    "### Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "gKXR7REP8C8s"
   },
   "outputs": [],
   "source": [
    "def mlp_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(50, input_shape = (784, ), kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))    \n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(10, kernel_initializer='he_normal'))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    adam = optimizers.Adam(learning_rate = 0.001)\n",
    "    model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8FJsCqh680bq",
    "outputId": "3546c1ba-bd70-4240-bbee-7ee7808bdb59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.8616 - accuracy: 0.7046\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.6073 - accuracy: 0.7925\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.5473 - accuracy: 0.8136\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.5188 - accuracy: 0.8233\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.4923 - accuracy: 0.8298\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.4757 - accuracy: 0.8383\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.4665 - accuracy: 0.8414\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.4591 - accuracy: 0.8424\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.4470 - accuracy: 0.8445\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.4407 - accuracy: 0.8484\n"
     ]
    }
   ],
   "source": [
    "model = mlp_model()\n",
    "history = model.fit(X_train, y_train, epochs = 10, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TY58JhC085IM",
    "outputId": "51508c12-b3f0-479f-bf40-c411cb3ac95c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 4ms/step - loss: 0.3940 - accuracy: 0.8557\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SU5NUjzs85KT",
    "outputId": "a9638d68-54a4-47ac-e01a-40d061b114d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.8557000160217285\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy: ', results[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "tb66vQo-KsM_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Image_Classification_Intro_to_NN_3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
